# Сравнение моделей для получения эмбеддингов  
  
Целью данного исследования является сравнение моделей векторизации из публичного лидерборда https://huggingface.co/spaces/mteb/leaderboard и модели векторизации all-MiniLM-L6-v2, которая является стандартной в Chroma DB.  

Сравнения будут проводиться для двух типов текстов: Изначально предложенные тексты про Telegram, Госуслуги и т.д. (делее Изначальные тексты) и Финансовые тексты. 

Также будет сравниваться работа моделей при разных вариантах хранения данных:
- Для изначальных текстов:
	1. Векторизуем вопрос и ответ вместе.
	2. Векторизуем только вопрос.
	3. Векторизуем только ответ.
	
- Для финансовых текстов:
	1. Вопрос задаётся на русском, текст документа храним на английском.
	2. Вопрос задаётся на английском, текст документа храним на английском.
  
# Ход работы:  
**Изначальные тексты.**  
1. *Генерация вопросов.*
	1. Из каждого текста выбираем по 3 вопроса. 
	2. Для каждого вопроса просим LLM 4 раза перефразировать вопрос с разными температурами (0, 0.5, 1, 1.2).  Таким образом получаем набор новых вопросов, которые ссылаются на изначальный чанк.
2. *Создание векторной базы данных.*
	1. Создаём векторную базу данных с использованием выбранного векторизатора.
	2. Добавляем в векторную базу данные согласно выбранному методу (векторизуем только вопросы, только ответы или всё вместе).
3. *Оценка качества.* 
	1. Векторизуем каждый новый вопрос.
	2. С помощью косинусного расстояния находим ближайшие чанки для данного вопроса.
	3. Определяем индекс истинного чанка для которого и был создан текущий вопрос.
	4. Сохраняем полученный индекс.
	5. После того, как будут обработаны все новые вопросы считаем средний ранг истинного чанка (берём среднее по всем полученным индексам).

Таким образом, можно оценить, на каком в среднем месте будет находится истинный чанк, для каждого из векторизаторов.

# Результаты
**Изначальные тексты.**
Для изначальных текстов были выбраны следующие векторизаторы:
- all-MiniLM-L6-v2 - стандартный векторизатор для Chroma DB.
- intfloat/multilingual-e5-large-instruct - одина из лучших моделей согласно лидерборду, которая имеет меньше всего параметров (нам важно, чтобы модель была небольшой).
- intfloat/multilingual-e5-small - укороченный аналог.

Итоги вычислений:

*Векторизуем вопрос + ответ.*
|Модель  |  Средний ранг истинного чанка (меньше - лучше)|
|--|--|
| multilingual-e5-small |  1.4|
|multilingual-e5-large-instruct |1.5|
|all-MiniLM-L6-v2|99.1|

*Храним только ответы.*
|Модель  |  Средний ранг истинного чанка (меньше - лучше)|
|--|--|
| multilingual-e5-small |  14.0|
|multilingual-e5-large-instruct |14.3|
|all-MiniLM-L6-v2|145|

*Xраним только вопросы.*

|Модель  |  Средний ранг истинного чанка (меньше - лучше)|
|--|--|
| multilingual-e5-small |  0.92|
|multilingual-e5-large-instruct |0.5|
|all-MiniLM-L6-v2|31.2|

![chart (1)](https://github.com/user-attachments/assets/b3067744-85a1-4f4e-98d4-590d5f8ddaa7)

Из результатов можно сделать  следующие**выводы**
- Лучше использовать модель **multilingual-e5-small**, так она меньше чем e5-large-instruct, и почти имеет одинаковое качество. 
- Лучше векторизовать **вопросы вместе с ответами**, так как качество векторизации уменьшается незначительно, но остаётся возможность вычислять вектор по вопросу и ответу. 
- all-MiniLM-L6-v2 плохо работает на русскоязычных текстах.
- Для изначальных текстов можно давать модели **3 чанка**.

**Финансовые документы.**
Для финансовых документов добавим специализированные финансовые векторизаторы:
- ohsuz/k-finance-sentence-transformer 
- baconnier/Finance2_embedding_small_en
- FinLang/finance-embeddings-investopedia
- philschmid/bge-base-financial-matryoshka 

*Вопрос задаётся на русском, текст на английском.*
|Модель  |  Средний ранг истинного чанка (меньше - лучше)|
|--|--|
| multilingual-e5-small |  10.6|
|multilingual-e5-large-instruct |9.4|
|all-MiniLM-L6-v2|401|
|k-finance-sentence-transformer|583|
|Finance2_embedding_small_en-V1.5|531|
|stella_en_400M_v5-FinanceRAG-v2|206|
|finance-embeddings-investopedia|456|
|bge-base-financial-matryoshka|418|

*Вопрос на английском, текст на английском.*
|Модель  |  Средний ранг истинного чанка (меньше - лучше)|
|--|--|
| multilingual-e5-small |  4.7|
|multilingual-e5-large-instruct |4.1|
|all-MiniLM-L6-v2|10.5|
|k-finance-sentence-transformer|246.2|
|Finance2_embedding_small_en-V1.5|68.8|
|stella_en_400M_v5-FinanceRAG-v2|27.1|
|finance-embeddings-investopedia|19.5|
|bge-base-financial-matryoshka|19.1|

![chart (2)](https://github.com/user-attachments/assets/e53074f1-d080-4875-b012-f23320806a9e)

# Выводы
Из результатов можно сделать следующие **выводы**
- Лучше использовать модель **multilingual-e5-small**.
- Специализированные векторизаторы не дали прироста качества на финансовых текстах. 
- Для финансовых текстов лучше **задавать вопрос на английском языке**. 
- Для финансовых текстов нужно давать модели **~6 чанков**.
- На изначальнах текстах достаточно давать модели **~3 чанка**.
